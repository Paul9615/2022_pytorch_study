{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector, Matrix, and Tensor\n",
    "+ vector: dimension 없는 값를 scalar 차원으로 구성된 값\n",
    "+ matrix: 2-dimension으로 구성되어 있는 값\n",
    "+ tensor: 3-dimension으로 구성되어 있는 값\n",
    "\\\n",
    "\\\n",
    "__DL을 할때 중요한 부분은 다루고 있는 matrix 또는 tensor 크기를 고려__\n",
    "+ 2D tensor: $|t| = (batch \\ size, \\ dim)$\n",
    "+ 3D tensor: $|t| = (batch \\ size , \\ width, \\ height)$\n",
    "    + 일반적인 vision 분야에서 다루게 됨\n",
    "    + NLP 경우: $|t| = (batch \\ size , \\ length, \\ dim)$ \n",
    "        + (batch size, length of sentence, dimension of vector of word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tensor with Numpy\n",
    "import numpy as np \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "# 1D with numpy\n",
    "t = np.array([0.,1.,2,3.,4.,5.,6.])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank of t:  1\n",
      "shape of t:  (7,)\n"
     ]
    }
   ],
   "source": [
    "# print rand and shape\n",
    "print('rank of t: ', t.ndim) # 몇 차원인지\n",
    "print('shape of t: ', t.shape) # 크기가 얼마인지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]\n",
      " [ 7.  8.  9.]\n",
      " [10. 11. 12.]]\n",
      "Rank of t: 2\n",
      "Shap of t: (4, 3)\n"
     ]
    }
   ],
   "source": [
    "# 2D with Numpy\n",
    "t = np.array([[1.,2.,3.], \n",
    "              [4.,5.,6.],\n",
    "              [7.,8.,9.],\n",
    "              [10.,11.,12.]])\n",
    "print(t)\n",
    "\n",
    "print(f\"Rank of t: {t.ndim}\")\n",
    "print(f\"Shap of t: {t.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "# 1D with Pytorch\n",
    "t = torch.FloatTensor([0.,1.,2.,3.,4.,5.,6.])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "print(t.dim()) # 차원\n",
    "print(t.shape) # = size(), 크기  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# 2D with Pytorch\n",
    "t = torch.FloatTensor([[1.,2.,3.],\n",
    "                       [4.,5.,6.],\n",
    "                       [7.,8.,9.],\n",
    "                       [10.,11.,12.]])\n",
    "\n",
    "print(t.dim())\n",
    "print(t.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting: 서로 다른 vector(or matrix)의 크기를 맞춰 operation을 수행하게 만듦\n",
    "m1 = torch.FloatTensor([[3,3]])\n",
    "m2 = torch.FloatTensor([[2,2]])\n",
    "\n",
    "print(m1+m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "# vector and scalar\n",
    "m1 = torch.FloatTensor([[1,2]])\n",
    "m2 = torch.FloatTensor([3])\n",
    "# pytorch의 경우 m2의 크기를 m1에 맞게 크기를 변경하여 연산 수행\n",
    "print(m1+m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# vector operation\n",
    "m1 = torch.FloatTensor([[1,2]])\n",
    "m2 = torch.FloatTensor([[3],[4]])\n",
    "\n",
    "# pytorch의 경우 두 벡터의 크기가 달라도 크기를 맞춰 연산을 수행함\n",
    "print(m1+m2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Matrix 1:  torch.Size([2, 2])\n",
      "Shape of Matrix 2:  torch.Size([2, 1])\n",
      "tensor([[ 5.],\n",
      "        [11.]])\n"
     ]
    }
   ],
   "source": [
    "# Difference between matrix multiplication and multiplication\n",
    "\n",
    "m1 = torch.FloatTensor([[1,2],[3,4]])\n",
    "m2 = torch.FloatTensor([[1],[2]])\n",
    "\n",
    "print('Shape of Matrix 1: ', m1.shape) # 2 x 2\n",
    "print('Shape of Matrix 2: ', m2.shape) # 2 x 1\n",
    "\n",
    "print(m1.matmul(m2)) # multiplication, 2 x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Matrix 1:  torch.Size([2, 2])\n",
      "Shape of Matrix 2:  torch.Size([2, 1])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# element-wise mutiplication: 동일한 크기의 행렬이 동일한 위치에 있는 원소끼리 곱하는 것\n",
    "\n",
    "print('Shape of Matrix 1: ', m1.shape) # 2 x 2\n",
    "print('Shape of Matrix 2: ', m2.shape) # 2 x 1\n",
    "print(m1 * m2) # 2 x 2\n",
    "print(m1.mul(m2)) # same with operator *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5000)\n"
     ]
    }
   ],
   "source": [
    "# Mean \n",
    "t = torch.FloatTensor([1,2])\n",
    "print(t.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5000)\n",
      "tensor([2., 3.])\n",
      "tensor([1.5000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1,2],[3,4]])\n",
    "\n",
    "print(t.mean())\n",
    "print(t.mean(dim=0)) # dim=0은 첫 번째 차원을 의미함 즉, 행임 e.g. 2 by 2 matrix -> 1 by 2, same with (2,)인 vector\n",
    "print(t.mean(dim=1)) # 열이 제거된 tensor가 되어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(10.)\n",
      "tensor([4., 6.])\n",
      "tensor([3., 7.])\n",
      "tensor([3., 7.])\n"
     ]
    }
   ],
   "source": [
    "# summation\n",
    "t = torch.FloatTensor([[1,2],[3,4]])\n",
    "print(t) # 2 by 2  matrix\n",
    "print(t.sum())\n",
    "print(t.sum(dim=0)) # 행 제거\n",
    "print(t.sum(dim=1)) # 열 제거\n",
    "print(t.sum(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n",
      "torch.return_types.max(\n",
      "values=tensor([3., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "tensor([3., 4.])\n",
      "tensor([2., 4.])\n"
     ]
    }
   ],
   "source": [
    "# maximum value \n",
    "print(t.max())\n",
    "print(t.max(dim=0)) # 행 제거, 열 기준의 최댓값 column 1의 최댓값은 3이고 column 2의 최댓값은 4이므로 3,4가 출력\n",
    "print(t.max(dim=1)) # 열 제거, 행 기준의 최댓값 row 1의 최댓값은 2이고 row 2의 최댓값은 4이므로 2, 4가 출력\n",
    "\n",
    "print(t.max(dim=0)[0])\n",
    "print(t.max(dim=1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View\n",
    "+ 원소의 수를 유지하면서 tensor의 크기 변경\n",
    "+ numpy에서 reshape와 같은 역할함, 크기를 변경해줌\n",
    "\n",
    "__Rules in view__\n",
    "+ view는 기본적으로 변경 전과 후의 tensor 안의 개수가 유지되어야 함\n",
    "+ torch의 view는 size가 -1로 설정되면 다른 차원으로부터 해당 값을 유추 \n",
    "    + 유추할 때 총 원소의 개수가 reshape 이전 원소의 개수가 동일해야 함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]]\n",
      "\n",
      " [[ 6  7  8]\n",
      "  [ 9 10 11]]]\n",
      "t shape: (2, 2, 3)\n",
      "ft shape: torch.Size([2, 2, 3])\n",
      "3 dim tensor to 2 dim tensor \n",
      " tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]])\n",
      "check size after change: torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# reshape in numpy VS  view in torch\n",
    "t = np.array([[[0,1,2],\n",
    "               [3,4,5]],\n",
    "              [[6,7,8],\n",
    "              [9,10,11]]]) # 3-dim tensor\n",
    "print(t)\n",
    "print(f't shape: {t.shape}')\n",
    "\n",
    "ft = torch.FloatTensor(t)\n",
    "print(f'ft shape: {ft.shape}')\n",
    "\n",
    "# 3 dim tensor to 2 dim tensor\n",
    "print(f'3 dim tensor to 2 dim tensor \\n {ft.view([-1,3])}') # reshape to (?,3)\n",
    "print(f'check size after change: {ft.view([-1,3]).shape}') # -1은 첫번째 dim은 임의로 설정하겠다는 의미임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squeeze\n",
    "+ dimension이 1인 경우 해당 차원을 제거한다\n",
    "\n",
    "# Unsqueeze\n",
    "+ squeeze와 반대\n",
    "+ 특정 위치에 1인 dimension을 추가한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "ft = torch.FloatTensor([[0],[1],[2]])\n",
    "print(ft)\n",
    "print(ft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2.])\n",
      "shape after squeeze: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# squeeze\n",
    "print(ft.squeeze())\n",
    "print(f'shape after squeeze: {ft.squeeze().shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.],\n",
      "         [1.],\n",
      "         [2.]]])\n",
      "torch.Size([1, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "# unsqueeze\n",
    "print(ft.unsqueeze(0)) # 첫 번째 차원 unsqueeze\n",
    "print(ft.unsqueeze(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.]])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "# unsqueeze same with view\n",
    "print(ft.view(1,-1)) # 2 dim으로 바꾸고 싶으면서 첫 번째 dim은 1이기 원한다면 view에 (1,-1)인자 사용\n",
    "print(ft.view(1,-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.]],\n",
      "\n",
      "        [[1.]],\n",
      "\n",
      "        [[2.]]])\n",
      "torch.Size([3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(ft.unsqueeze(-1))\n",
    "print(ft.unsqueeze(-1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type casting\n",
    "+ 자료형을 변환하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "lt = torch.LongTensor([1,2,3,4])\n",
    "print(lt.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# change type to float\n",
    "print(lt.float())\n",
    "print(lt.float().dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate\n",
    "+ 두 tensor를 연결\n",
    "+ DL에서 두 tensor를 연결하여 입력으로 사용함. \n",
    "    + 두 정보를 모두 사용한다는 의미임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.],\n",
      "        [7., 8.]])\n",
      "tensor([[1., 2., 5., 6.],\n",
      "        [3., 4., 7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1,2],\n",
    "                       [3,4]])\n",
    "y = torch.FloatTensor([[5,6],\n",
    "                       [7,8]])\n",
    "\n",
    "print(torch.cat([x,y],dim=0)) # 첫 번째 차원을 늘림, 2 by 2 to 4 by 2\n",
    "print(torch.cat([x,y],dim=1)) # 2 by 2 to 2 by 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "+ concatenate를 하는 또 다른 방법임\n",
    "+ 일반적인 concatenate보다 더 많은 연산을 포함하고 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n",
      "same with above \n",
      " tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]]) \n",
      "\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([1,4])\n",
    "y = torch.FloatTensor([2,5])\n",
    "z = torch.FloatTensor([3,6])\n",
    "\n",
    "print(torch.stack([x,y,z]))\n",
    "print(f'same with above \\n {torch.cat([x.unsqueeze(0), y.unsqueeze(0), z.unsqueeze(0)], dim=0)} \\n')\n",
    "\n",
    "# increase to 2 dimension\n",
    "print(torch.stack([x,y,z], dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ones_like and zeros_like\n",
    "+ Ones_like: 1로 채워진 tensor\n",
    "+ zeros_like: 0으로 채워진 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [2., 1., 0.]]) \n",
      "\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[0,1,2],[2,1,0]])\n",
    "print(f'{x} \\n')\n",
    "\n",
    "# fill up with one\n",
    "print(f'{torch.ones_like(x)} \\n')\n",
    "\n",
    "# fill up with zero\n",
    "print(torch.zeros_like(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-place Operation\n",
    "+ 덮어쓰기 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1,2],[3,4]])\n",
    "\n",
    "print(x.mul(2.))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# in place operator _ (under bar)\n",
    "print(x.mul_(2.))\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1e5884059a9e58218085a732887c585e94818ab84f9336d4151624cf315f1a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
