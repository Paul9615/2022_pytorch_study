{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Regression\n",
    "## Multi-class Classification\n",
    "+ Binary classification problem과 달리 3개 이상의 다중 클래스 분류에서 활용됨\n",
    "    + e.g. iris data에서 4개의 feature를 통해 4개의 iris 품종을 classification할 때\n",
    "+ 클래스에 부여된 확률의 총 합이 1이 되도록 각 클래스에 확률 부여\n",
    "    + class가 3개일 때 softamax fucntion을 통해 3-dim. vector를 원소의 총합이 1이 되도록 원소들의 값이 변환\\\n",
    "    $H(x) = softmax(WX+B)$ \n",
    "\n",
    "## Softmax Function \n",
    "+ 분류해야하는 class의 총 개수를 k라고 할 때, k-dim.의 vector를 입력받아 각 class에 대한 확률을 추정함\\\n",
    "$p_i = \\frac{e^{z_i}}{\\sum_{j=1}^k e^{z_j}}$\n",
    "    + $z_i$: k-dim.의 vector에서 i번째 원소\n",
    "    + $p_i$: i번째 class가 정답일 확률을 \n",
    "    + k=3일 때, 3 dim. vector $z=[z_1, z_2, z_3]$\\\n",
    "    $softmax(z) = [\\frac{e^{z_1}}{\\sum_{j=1}^3 e^{z_j}} \\frac{e^{z_2}}{\\sum_{j=1}^3 e^{z_j}} \\frac{e^{z_3}}{\\sum_{j=1}^3 e^{z_j}}] = [p_1, p_2, p_3] = \\hat{y} = predict \\ value$\n",
    "\n",
    "## Cost function\n",
    "__Cross Entropy Function__\\\n",
    "$cost(W)=-\\frac{1}{n} \\sum_{i=1}^n \\sum_{j=1}^k y_j^{(i)} \\log{(p_j^{(i)})}$\\\n",
    "+ $-\\sum_{j=1}^k y_j \\log{(p_J)}$ 값을 최소화하는 방향으로 학습해야하기 때문\n",
    "    + 실제값과 예측값의 차이가 별로 없을 때 위의 식이 0에 가까워야 함\n",
    "\n",
    "__Cross Entropy Function in Binary classification__\n",
    "+ if k=2\\\n",
    "$cost(w) = -\\frac{1}{n} \\sum_{i=1}^n [y^{(i)}\\log(p^{(i)})+(1-y^{(i)})\\log(1-p^{(i)})]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1ec3013faf0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "x_train = [[1, 2, 1, 1],\n",
    "           [2, 1, 3, 2],\n",
    "           [3, 1, 3, 4],\n",
    "           [4, 1, 5, 5],\n",
    "           [1, 7, 5, 5],\n",
    "           [1, 2, 5, 6],\n",
    "           [1, 6, 6, 6],\n",
    "           [1, 7, 7, 7]] # 8 by 4\n",
    "y_train = [2, 2, 2, 1, 1, 1, 0, 0] # 8 by 1\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.LongTensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 0.000000\n",
      "Epoch  100/1000 Cost: 0.000000\n",
      "Epoch  200/1000 Cost: 0.000000\n",
      "Epoch  300/1000 Cost: 0.000000\n",
      "Epoch  400/1000 Cost: 0.000000\n",
      "Epoch  500/1000 Cost: 0.000000\n",
      "Epoch  600/1000 Cost: 0.000000\n",
      "Epoch  700/1000 Cost: 0.000000\n",
      "Epoch  800/1000 Cost: 0.000000\n",
      "Epoch  900/1000 Cost: 0.000000\n",
      "Epoch 1000/1000 Cost: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# implement on low level\n",
    "\n",
    "# one-hot encodding\n",
    "y_one_hot = torch.zeros(8,3) # number of class 3\n",
    "y_one_hot.scatter(1,y_train.unsqueeze(1),1) # 새로 구성한 tensor에 원하는 index에 맞게 값을 할당 해줌 \n",
    "\n",
    "# initialize model \n",
    "w = torch.zeros((4,3), requires_grad=True) \n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# optimizer\n",
    "opt = optim.SGD([w,b], lr=0.1)\n",
    "\n",
    "# number of epoch \n",
    "n_epoch = 1000 \n",
    "\n",
    "for epoch in range(n_epoch+1):\n",
    "    hyp = F.softmax(x_train.matmul(w)+b, dim=1)\n",
    "    cost = (y_one_hot * -torch.log(hyp)).sum(dim=1).mean()\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    cost.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch:4d}/{n_epoch} Cost: {cost.item():.6f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.098612\n",
      "Epoch  100/1000 Cost: 0.761050\n",
      "Epoch  200/1000 Cost: 0.689991\n",
      "Epoch  300/1000 Cost: 0.643229\n",
      "Epoch  400/1000 Cost: 0.604117\n",
      "Epoch  500/1000 Cost: 0.568255\n",
      "Epoch  600/1000 Cost: 0.533922\n",
      "Epoch  700/1000 Cost: 0.500291\n",
      "Epoch  800/1000 Cost: 0.466908\n",
      "Epoch  900/1000 Cost: 0.433507\n",
      "Epoch 1000/1000 Cost: 0.399962\n"
     ]
    }
   ],
   "source": [
    "# implement on high level \n",
    "\n",
    "# initialize model \n",
    "w = torch.zeros((4,3), requires_grad=True) \n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# optimizer\n",
    "opt = optim.SGD([w,b], lr=0.1)\n",
    "\n",
    "# number of epoch \n",
    "n_epoch = 1000 \n",
    "\n",
    "for epoch in range(n_epoch+1):\n",
    "    z = x_train.matmul(w)+b\n",
    "    cost = F.cross_entropy(z, y_train)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    cost.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch:4d}/{n_epoch} Cost: {cost.item():.6f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 3.763306\n",
      "Epoch  100/1000 Cost: 0.634510\n",
      "Epoch  200/1000 Cost: 0.553141\n",
      "Epoch  300/1000 Cost: 0.499127\n",
      "Epoch  400/1000 Cost: 0.454847\n",
      "Epoch  500/1000 Cost: 0.415295\n",
      "Epoch  600/1000 Cost: 0.378128\n",
      "Epoch  700/1000 Cost: 0.341821\n",
      "Epoch  800/1000 Cost: 0.305279\n",
      "Epoch  900/1000 Cost: 0.268723\n",
      "Epoch 1000/1000 Cost: 0.242802\n"
     ]
    }
   ],
   "source": [
    "# implement with nn.Module \n",
    "mod = nn.Linear(4,3)\n",
    "opt=optim.SGD(mod.parameters(), lr=0.1)\n",
    "\n",
    "n_epoch = 1000\n",
    "\n",
    "for epoch in range(n_epoch+1):\n",
    "    pred = mod(x_train)\n",
    "    cost = F.cross_entropy(pred, y_train)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    cost.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch:4d}/{n_epoch} Cost: {cost.item():.6f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement with class \n",
    "# model\n",
    "class SoftmaxClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(4,3)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "mod = SoftmaxClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 0.242658\n",
      "Epoch  100/1000 Cost: 0.230196\n",
      "Epoch  200/1000 Cost: 0.219127\n",
      "Epoch  300/1000 Cost: 0.209044\n",
      "Epoch  400/1000 Cost: 0.199820\n",
      "Epoch  500/1000 Cost: 0.191348\n",
      "Epoch  600/1000 Cost: 0.183541\n",
      "Epoch  700/1000 Cost: 0.176324\n",
      "Epoch  800/1000 Cost: 0.169633\n",
      "Epoch  900/1000 Cost: 0.163413\n",
      "Epoch 1000/1000 Cost: 0.157618\n"
     ]
    }
   ],
   "source": [
    "opt = optim.SGD(mod.parameters(), lr=0.1)\n",
    "n_epoch = 1000\n",
    "\n",
    "for epoch in range(n_epoch+1):\n",
    "    pred = mod(x_train)\n",
    "    cost = F.cross_entropy(pred, y_train)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    cost.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch:4d}/{n_epoch} Cost: {cost.item():.6f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1e5884059a9e58218085a732887c585e94818ab84f9336d4151624cf315f1a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
