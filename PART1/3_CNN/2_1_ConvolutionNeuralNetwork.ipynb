{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Nueral Network (CNN)\n",
    "### !신호 및 시스템에서 convloution 개념 이해하기!\n",
    "__참고__\\\n",
    "https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=hafs_snu&logNo=221236902235\\\n",
    "https://www.youtube.com/watch?v=uXl_QTsTj-w\n",
    "+ convolution은 LTI system에서 어떤 impulse 신호들의 반응(impulse response)의 합 \n",
    "    + $x[n] = ... + x[-2]\\delta[n+2]+x[-1]\\delta[n+1]+x[0]\\delta[n]+...$\\\n",
    "      $-> System -> y[n]=\\sum_{k=-\\infin}^{\\infin}x[k]h[n-k]$ \n",
    "        + $y[n]$에서 $x[k]$: Scaling $-k$: Time Invariant\n",
    "\n",
    "## Convolution과 Pooling\n",
    "### Why CNN?\n",
    "+ image와 같은 2차원 이상의 데이터를 1차원으로 변환하면 원본을 파악하기 힘듦\n",
    "+ image와 같은 2차원 이상의 데이터에 대한 spatial structure(공간적인 구조)를 보존하며 학습하는 방법이 필요해짐\n",
    "\n",
    "### Chennel\n",
    "+ image tensor의 구성: (Height, Width, Chennel)\n",
    "    + Height: image의 세로 방향 pixel 수\n",
    "    + Width: image의 가로 방향 pixel 수\n",
    "    + Chennel(depth): 색 성분\n",
    "    + 각 pixel은 0~255 사이의 값을 가짐\n",
    "\n",
    "### Convolution Operation\n",
    "+ convolution layer: input에 대한 convolution operation을 통해 image의 특징을 추출하는 역할 수행\n",
    "    + kernel(=filter)을 이용해 image를 가장 왼쪽 위부터 가장 오른쪽까지 순차적으로 kernel 크기만큼 훑음 \n",
    "    + kernel 크기의 겹쳐지는 부분의 각 image와 kernel의 원소의 값을 곱해서 모두 더한 값을 출력으로 함 \n",
    "        + kernel: $n \\times m \\ ( e.g. \\ height \\times width)$ 크기의 matrix\n",
    "            + 일반적으로 $3 \\times 3$ 또는 $5 \\times 5$ 사용\n",
    "        + Stride: convolution operation을 하면서 operation step을 옮기는 크기(이동하는 범위) \n",
    "    + kernel을 이용하여 convolution operation을 끝나면 결과물로 feature map이 나옴\n",
    "        + convolution operation을 9번 수행하고(kernel이 $3 \\times 3$), stride가 1일 때 $3 \\times 3$ 크기의 feature map이 나옴   \n",
    "\n",
    "### Padding\n",
    "+ convolution operation 이전 input의 가장자리에 지정된 개수의 폭만큼 row와 column을 추가\n",
    "    + 주로 0으로 채움(zero padding)\n",
    "\n",
    "<img src=\"https://wikidocs.net/images/page/64066/conv10.png\">\n",
    "\n",
    "+ covolution operation 이후 feature map의 크기와 input의 크기가 동일하게 유지하기 위해서 사용\n",
    "+ 만약 stride가 1이고 $3 \\times 3$ 크기의 kernel을 사용할 때 1폭짜리 padding 사용\\\n",
    "  $5 \\times 5$ 크기의 kernel을 사용할 때 2폭짜리 padding 사용  \n",
    "\n",
    "### Weighted and Bias\n",
    "__Weighted__\n",
    "+ MLP에선 input image가 3x3이고 hidden layer의 neuron이 4개면 9x4 = 36개의 weighted를 가짐\n",
    "+ CNN 의 경우 kernel의 크기에 따라 weighted 수가 정해짐\n",
    "    + 예로 kernel의 크기가 2x2면 4개의 weighted를 가짐\n",
    "    + 각 convolution마다 image의 모든 pixel을 사용하는 것이 아닌 kernel과 mapping되는 pixel만을 input으로 사용\n",
    "        + MLP보다 훨씬 더 적은 수의 weighted를 사용하여 공간적 구조 정보를 보존\n",
    "+ hidden layer에서 kernel을 통해 얻은 feature map을 non-linearity를 추가하기 위해 activation function을 통과\n",
    "    + ReLu function이나 그 변형들이 사용됨 \n",
    "+ Convolution layer: convolution operation을 통해 feature map을 얻고 activation function을 지나는 일련의 operation을 하는 hidden layer\n",
    "\n",
    "__Bias__\n",
    "+ kernel을 적용한 후 bias를 더함\n",
    "+ bias는 하나의 값만 존재, kernel이 적요ㅇ된 결과의 모든 원소에 더해짐 \n",
    "\n",
    "### Feature map\n",
    "+ input, kernel의 size와 stride의 값을 알면 feature map의 size를 계산할 수 있음\n",
    "    + feature map의 height와 wiftd\n",
    "        + $O_h = floor (\\frac{I_h - K_h}{S}+1)$\n",
    "        + $O_w = floor (\\frac{I_w - K_w}{S}+1)$\n",
    "            + $O_h$: height of feature map  $O_w$: width of feature map \n",
    "            + $I_h$: height of input    $I_w$: width of input\n",
    "            + $K_h$: height of kernel   $K_w$: width of kernel \n",
    "            + $S$: stride   $floor$: 소수점 발생 시 소수점 이하를 버림\n",
    "    + padding까지 고려한 식\n",
    "        + $O_h = floor (\\frac{I_h - K_h + 2P}{S}+1)$\n",
    "        + $O_d = floor (\\frac{I_w - K_w + 2P}{S}+1)$\n",
    "            + $P$: padding의 폭\n",
    "            + 왜 padding의 폭을 2 times 해주는지 알아보기\n",
    "\n",
    "### Convolution operation with Multi-channel case\n",
    "+ input의 channel의 수와 kernel의 channel의 수는 같아야 함\n",
    "    + channel의 수가 같아야 convolution operation을 channel마다 수행함\n",
    "    + 각 convolution operation을 수행 후 나온 각 feature map을 더하여 최종 feature map을 얻음\n",
    "\n",
    "__Convolution operation on 3D tensor__\\\n",
    "<img src=\"https://wikidocs.net/images/page/64066/conv16_final.png\">\n",
    "\n",
    "+ 위 사진에서 input의 $I_h$, $I_w$, channel $C_i$는 동일한 channel의 수 $C_i$를 가지는 $K_h \\times K_w \\times C_i$ 크기의 kernel을 convolution operation하여 $O_h \\times O_w \\times 1$(channel이 1) 크기의 feature map을 얻음 \n",
    "+ convolution operation에서 다수의 kernel을 사용할 때, 사용한 kernel 수는 convolution operation의 결과로 나오는 feature map의 channel 수가 됨\n",
    "+ number of weighted\n",
    "    + $K_i \\times K_o \\times C_i \\times C_o \\times$\n",
    "    + $K_i$: input\n",
    "\n",
    "### Pooling\n",
    "+ pooling operation\n",
    "    + max pooling: kernel과 겹치는 영역 안에서 최대값을 추출하는 방식으로 down sampling\n",
    "    + average pooling: kernel과 겹치는 영역 안에서 평균값을 추출하는 방식으로 down sampling\n",
    "+ pooling layer는 convolution layer 다음에 추가됨\n",
    "+ pooling layer에서 feature map을 down sampling하여 feature map의 size를 줄임\n",
    "+ convolution operation과 달리 training해야 할 weighted가 없고 operation 후에 channel의 수가 변하지 않음\n",
    "\n",
    "# Implement MNIST classifier using CNN\n",
    "## Understanding model\n",
    "1. First case\n",
    "+ convolution(nn.Conv2d) + activation function(nn.Relu())를 하나의 layer로, Max pooling(nn.MaxPoold2d)은 pooling layer로 따로\n",
    "2. Second case\n",
    "+ convolution(nn.Conv2d) + activation function(nn.Relu())+Max pooling(nn.MaxPoold2d)\n",
    "\n",
    "__In this page, I used 2nd case__\n",
    "1. 1st layer: Convolution layer\n",
    "+ Convolution(in_channel = 1, out_channel = 32, kernel_size=3, stride=1, padding=1) + Activation function ReLU\\\n",
    "Max pooling(kernel_size=2, stride=2))\n",
    "\n",
    "2. 2nd layer: Convolution layer\n",
    "+ Convolution(in_channel = 32, out_channel = 64, kernel_size=3, stride=1, padding=1) + Activation function ReLU\\\n",
    "Max pooling(kernel_size=2, stride=2))\n",
    "\n",
    "3. 3rd layer: Fully Connected layer\n",
    "+ Feature map을 펼친다. # batch_size × 7 × 7 × 64 → batch_size × 3136\\\n",
    "Fully connected layer(number of 10 neurons) + Activation function Softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of tensor: torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# implementaion simple model\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "# make tensor randomly \n",
    "inputs = torch.Tensor(1, 1, 28, 28) # batch size x channel x height x width\n",
    "print(f'size of tensor: {inputs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "# declare convolution layer and pooling\n",
    "conv1 = nn.Conv2d(1,32,3,padding=1) # input channel = 1, output channel = 32, kernel size = 3, padding = 1\n",
    "# print(conv1)\n",
    "conv2 = nn.Conv2d(32,64, 3,padding=1) # input channel = 32, output channel = 64, kernel size = 3, padding = 1\n",
    "# print(conv2)\n",
    "pool = nn.MaxPool2d(2) # kernel size and stride are 2\n",
    "# print(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# make model to connecting with implementation\n",
    "\n",
    "# pass through the first convolution layer \n",
    "out = conv1(inputs)\n",
    "# print(out.shape) # padding is 1, channel is 32(set to 32 channels before), and width and height are 28 for each  \n",
    "\n",
    "# pass through the pooling \n",
    "out = pool(out)\n",
    "# print(out.shape) # padding is 1, channel is 32, and width and height are 14 for each\n",
    "\n",
    "# pass through the second convolution layer\n",
    "out = conv2(out)\n",
    "# print(out.shape) # padding is 1, channel is 64, and width and height are 14 for each\n",
    "\n",
    "# pass through the pooling\n",
    "out = pool(out)\n",
    "# print(out.shape) # padding is 1, channel is 64, and width and height are 7 for each\n",
    "\n",
    "# check first dimension of result\n",
    "# out.size(0)\n",
    "\n",
    "# tensor 펼치기\n",
    "out = out.view(out.size(0), -1) # batch dimention을 제외한 모두 하나의 차원으로 integrated\n",
    "# print(out.shape)\n",
    "\n",
    "# pass through the fully connected layer\n",
    "fc = nn.Linear(3136,10) # set to 10 neurons\n",
    "out = fc(out)\n",
    "print(out.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1e5884059a9e58218085a732887c585e94818ab84f9336d4151624cf315f1a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
